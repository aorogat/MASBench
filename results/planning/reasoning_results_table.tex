\setlength{\tabcolsep}{4pt}
\begin{table*}[t]
\centering
\footnotesize
\caption{Reasoning results across benchmarks with different LLMs. This experiment is designed to measure the effectiveness of CrewAI’s \emph{reasoning} feature by comparing performance in two modes: \xmark = execution without reasoning, \checkmark = with predefined reasoning, and F = cases where the model failed to follow CrewAI’s required reasoning output format. Metrics reported include accuracy, runtime (mean / total), and token usage.}
\vspace{-3mm}
\label{tab:reasoning-results}
\begin{tabular}{llcc|cc|cc}
\toprule
\multirow{2}{*}{\textbf{LLM}} & \multirow{2}{*}{\textbf{Metric}} & \multicolumn{2}{c|}{\textbf{GSM8K}} & \multicolumn{2}{c|}{\textbf{CSQA}} & \multicolumn{2}{c}{\textbf{MATH-100}} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8}
 & & \xmark & \checkmark & \xmark & \checkmark & \xmark & \checkmark \\
\midrule
\multicolumn{8}{c}{\textbf{Local Models}} \\
\midrule
\multirow{3}{*}{deepseek-llm:7b} 
 & Runtime (sec)  & \minmaxmean{0.75}{164.78}{18.15}{23935.76} & \minmaxmean{8.56}{647.44}{56.43}{74437.02} & \minmaxmean{0.33}{52.19}{3.31}{4037.68} & \minmaxmean{5.34}{314.34}{43.96}{53678.87} & \minmaxmean{2.44}{206.39}{54.10}{5410.02} & \minmaxmean{37.35}{983.63}{153.69}{15369.09} \\
 & Tokens  & \minmaxmean{0.00}{2143.00}{113.25}{149380.00} & \minmaxmean{0.00}{1040.00}{72.88}{96124.00} & \minmaxmean{1.00}{526.00}{22.72}{27736.00} & \minmaxmean{0.00}{698.00}{20.19}{24656.00} & \minmaxmean{1.00}{1071.00}{218.23}{21823.00} & \minmaxmean{0.00}{559.00}{97.41}{9741.00} \\
 & Accuracy (\%)  & 23.12 & \accChange{23.12}{15.39} $^{(25.47\%F)}$ & 42.83 & \accChange{42.83}{27.93} $^{(0.00\%F)}$ & 9.00 & \accChange{9.00}{3.00} $^{(40.00\%F)}$ \\
\midrule
\multirow{3}{*}{llama3.1:8b} 
 & Runtime (sec)  & \minmaxmean{3.47}{600.31}{31.96}{42150.01} & \minmaxmean{26.62}{1150.28}{201.13}{265288.72} & \minmaxmean{3.21}{30.15}{3.58}{4369.17} & \minmaxmean{20.82}{814.96}{112.16}{136945.64} & \minmaxmean{3.70}{600.27}{76.38}{7637.65} & \minmaxmean{40.41}{1728.45}{337.49}{33748.87} \\
 & Tokens  & \minmaxmean{0.00}{1218.00}{110.82}{146174.00} & \minmaxmean{0.00}{2745.00}{65.25}{86062.00} & \minmaxmean{1.00}{50.00}{1.29}{1573.00} & \minmaxmean{0.00}{124.00}{1.62}{1983.00} & \minmaxmean{0.00}{2114.00}{215.25}{21525.00} & \minmaxmean{0.00}{1403.00}{124.40}{12440.00} \\
 & Accuracy (\%)  & 52.92 & \accChange{52.92}{50.27} $^{(10.54\%F)}$ & 68.14 & \accChange{68.14}{63.72} $^{(0.00\%F)}$ & 25.00 & \accChange{25.00}{24.00} $^{(19.00\%F)}$ \\
\midrule
\multirow{3}{*}{phi4:14b} 
 & Runtime (sec)  & \minmaxmean{20.23}{173.06}{59.13}{77988.88} & \textcolor{red}{X} & \minmaxmean{22.50}{90.03}{46.68}{56998.23} & \minmaxmean{115.67}{600.24}{190.98}{233189.35} & \minmaxmean{30.70}{345.57}{110.75}{11074.69} & \minmaxmean{121.78}{666.89}{327.62}{32762.45} \\
 & Tokens  & \minmaxmean{1.00}{98.00}{1.09}{1442.00} & \textcolor{red}{X} & \minmaxmean{1.00}{128.00}{1.40}{1714.00} & \minmaxmean{0.00}{528.00}{3.43}{4187.00} & \minmaxmean{1.00}{1079.00}{21.09}{2109.00} & \minmaxmean{0.00}{605.00}{14.55}{1455.00} \\
 & Accuracy (\%)  & 89.46 & \textcolor{red}{X} & 75.68 & \accChange{75.68}{81.33} $^{(0.00\%F)}$ & 72.00 & \accChange{72.00}{50.00} $^{(21.00\%F)}$ \\
\midrule
\multirow{3}{*}{qwen:7b} 
 & Runtime (sec)  & \minmaxmean{2.63}{116.26}{20.43}{26943.80} & \minmaxmean{0.00}{711.41}{45.79}{60399.04} & \minmaxmean{2.55}{46.37}{5.94}{7253.45} & \minmaxmean{33.07}{475.78}{107.90}{131743.05} & \minmaxmean{9.06}{263.54}{50.11}{5010.91} & \minmaxmean{33.60}{543.87}{146.13}{14613.38} \\
 & Tokens  & \minmaxmean{1.00}{519.00}{80.32}{105947.00} & \minmaxmean{0.00}{926.00}{16.16}{21320.00} & \minmaxmean{1.00}{280.00}{9.44}{11526.00} & \minmaxmean{0.00}{281.00}{11.42}{13944.00} & \minmaxmean{1.00}{1161.00}{182.41}{18241.00} & \minmaxmean{0.00}{720.00}{65.05}{6505.00} \\
 & Accuracy (\%)  & 10.99 & \accChange{10.99}{2.88} $^{(84.69\%F)}$ & 25.88 & \accChange{25.88}{15.72} $^{(0.00\%F)}$ & 9.00 & \accChange{9.00}{4.00} $^{(70.00\%F)}$ \\
\midrule
\multicolumn{8}{c}{\textbf{Remote Models}} \\
\midrule
\multirow{3}{*}{gpt-4.1} 
 & Runtime (sec)  & \minmaxmean{0.90}{27.36}{2.74}{3612.95} & \minmaxmean{2.98}{84.95}{6.60}{8702.99} & \minmaxmean{0.71}{41.95}{2.63}{3208.67} & \minmaxmean{3.61}{52.18}{7.64}{9325.96} & \minmaxmean{0.77}{120.84}{11.44}{1144.02} & \minmaxmean{4.60}{125.64}{13.75}{1375.10} \\
 & Tokens  & \minmaxmean{1.00}{23.00}{1.03}{1357.00} & \minmaxmean{1.00}{53.00}{1.04}{1377.00} & \minmaxmean{1.00}{1.00}{1.00}{1221.00} & \minmaxmean{1.00}{1.00}{1.00}{1221.00} & \minmaxmean{1.00}{70.00}{3.75}{375.00} & \minmaxmean{1.00}{26.00}{3.02}{302.00} \\
 & Accuracy (\%)  & 90.67 & \accChange{90.67}{78.70} $^{(0.00\%F)}$ & 87.06 & \accChange{87.06}{87.31} $^{(0.00\%F)}$ & 86.00 & \accChange{86.00}{60.00} $^{(0.00\%F)}$ \\
\midrule
\multirow{3}{*}{gpt-4o-mini} 
 & Runtime (sec)  & \minmaxmean{0.54}{49.53}{5.61}{7402.36} & \minmaxmean{2.54}{45.27}{8.37}{11040.59} & \minmaxmean{0.49}{7.68}{1.57}{1922.32} & \minmaxmean{2.34}{27.02}{7.52}{9185.59} & \minmaxmean{0.66}{35.55}{11.63}{1162.81} & \minmaxmean{6.72}{66.62}{21.18}{2118.43} \\
 & Tokens  & \minmaxmean{1.00}{197.00}{1.15}{1516.00} & \minmaxmean{1.00}{6.00}{1.01}{1326.00} & \minmaxmean{1.00}{5.00}{1.00}{1227.00} & \minmaxmean{1.00}{1.00}{1.00}{1221.00} & \minmaxmean{1.00}{19.00}{2.37}{237.00} & \minmaxmean{1.00}{330.00}{6.08}{608.00} \\
 & Accuracy (\%)  & 81.80 & \accChange{81.80}{86.73} $^{(0.00\%F)}$ & 81.65 & \accChange{81.65}{81.33} $^{(0.00\%F)}$ & 60.00 & \accChange{60.00}{53.00} $^{(0.00\%F)}$ \\
\midrule
\bottomrule
\end{tabular}
\end{table*}